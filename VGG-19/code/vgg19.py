# -*- coding: utf-8 -*-
"""VGG19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fP8Oi5rEDKBb-VtWxV8J-zSf5mMdx8Ze

### VGG-19


This code is a reference for future implementations of VGG-19 pre-trained, IÂ´m not find performance model, But focus is of the architecture for implement a tranfer-learning solution. 


<br>
<hr>
"""

# Commented out IPython magic to ensure Python compatibility.
import os 
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 
import matplotlib.image as mpimg
import seaborn as sns
import glob
import time 
from PIL import Image
from scipy import ndimage, misc
import cv2 

# %matplotlib inline 
import warnings
warnings.filterwarnings("ignore")



import tensorflow as tf
from tensorflow import keras 
import tensorflow_hub as hub
import tensorflow_datasets as tfds
from keras.datasets import cifar10
from tensorflow.keras.layers import Input
from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.utils import get_file
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, GlobalMaxPool2D, Dropout 
from tensorflow.keras.models import Model
from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy
from tensorflow.keras.applications import VGG19
from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions
from sklearn.metrics import classification_report

# seed 
np.random.seed(42)
tf.random.set_seed(42)

print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

(X_train, y_train), (X_test, y_test) = cifar10.load_data()

teste = array_to_img(X_train[4])
plt.imshow(teste)

image =  array_to_img(X_train[0])
image.size

class_names = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]

plt.figure(figsize=(12,6))

for image in range(0,4):
  plt.subplot(2,2, image + 1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(X_train[image])
plt.show()

# scaling pixels 
X_train = X_train.astype(np.float32) / 255.0
X_test = X_test.astype(np.float32) / 255.0

X_train.shape

# vector for binary matrix 
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

"""<hr>
<br>



#### VGG-19




<br>
"""

# VGG-19 architecture
vgg = VGG19(include_top=False, weights='imagenet', input_shape=(32, 32, 3), pooling='max', classes=10)

# setting trainable layers in VGG-19 

for layer in vgg.layers[0:15]:
  layer.trainable = True

for layer in vgg.layers[15:]:
  layer.trainable = False

# Summary VGG-19
print(vgg.summary())

# Build CNN 

model = Sequential()
model.add(vgg)
model.add(Dense(250, activation="relu"))
model.add(Dropout(0.30))
model.add(Dense(10, activation="softmax"))

model.summary()

model.compile(optimizer=Adam(0.001),
              loss=CategoricalCrossentropy(),
              metrics=["accuracy"])

model.fit(X_train, y_train,
          epochs=10,
          batch_size=128,
          validation_data=(X_test, y_test))

"""<br>
<hr>
"""